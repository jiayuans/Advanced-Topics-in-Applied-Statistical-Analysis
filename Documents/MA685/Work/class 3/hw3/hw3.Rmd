---
title: "MA685 HW3"
author: "Jiayuan Shi"
date: "Feb 20, 2016"
output: pdf_document
---

## Exercise 1 (Conceptional: Training and Test Error)  
Exercise 8 (p. 170): Compare logistic regression and KNN based on error rates.  

For KNN with K=1, we have a training error rate of 0%, because for any training observation, its nearest neighbor will be the response itself, and we do not make any error on the training data. However, we have an average error rate of 18%, so KNN has a test error rate of 36%, which is greater than the test error rate for logistic regression of 30%. Based on these results, we should prefer logistic regression because of its lower test error rate.

## Exercise 2 (Conceptional: Odds)  
Exercise 9 (p. 170): Interpretation using odds.  

### (a)  
$$
\begin{aligned}
odds = \frac{p(X)}{1 - p(X)} = 0.37\\ 
p(X) = 0.37(1 - p(X))\\
1.37 p(X) = 0.37\\  
p(X) = \frac{0.37}{1.37} = 27\% 
\end{aligned}
$$
On average, 27% of people with an odds of 0.37 of defaulting on their credit card payment will in fact default.

### (b)
$$
odds = \frac{p(X)}{1 - p(X)} = \frac{0.16}{1 - 0.16} = 19\%
$$
The odds that she will default is 19%.

## Exercise 3 (Applied: Comparison of Classification Methods I)
Exercise 11 (p. 171): Perform a comparison of classification methods using the Auto data set.

### (a)
```{r}
library(ISLR)
attach(Auto)
mpg01 <- rep(0, length(mpg))
mpg01[mpg > median(mpg)] <- 1
Auto <- data.frame(Auto, mpg01)
```

### (b)
```{r}
cor(Auto[,-9])
pairs(Auto)
boxplot(cylinders ~ mpg01, data = Auto, main = "Cylinders vs mpg01")
boxplot(displacement ~ mpg01, data = Auto, main = "Displacement vs mpg01")
boxplot(horsepower ~ mpg01, data = Auto, main = "Horsepower vs mpg01")
boxplot(weight ~ mpg01, data = Auto, main = "Weight vs mpg01")
boxplot(acceleration ~ mpg01, data = Auto, main = "Acceleration vs mpg01")
boxplot(year ~ mpg01, data = Auto, main = "Year vs mpg01")
```
There exists some association between mpg01 and cylinders, displacement, horsepower, weight.

### (c)
```{r}
train <- (year %% 2 == 0)
Auto.train <- Auto[train, ]
Auto.test <- Auto[!train, ]
mpg01.test <- mpg01[!train]
```

### (d)
```{r}
# LDA
library(MASS)
fit.lda <- lda(mpg01 ~ cylinders+weight+displacement+horsepower,
              data=Auto, subset=train)
fit.lda
pred.lda <- predict(fit.lda, Auto.test)
mean(pred.lda$class != mpg01.test)
```
The test error of the model obtained is 12.64%

### (e)
```{r}
# QDA
fit.qda <- qda(mpg01~cylinders+weight+displacement+horsepower,
              data=Auto, subset=train)
fit.qda
pred.qda <- predict(fit.qda, Auto.test)
mean(pred.qda$class != mpg01.test)
```
The test error of the model obtained is 13.19%

### (f)
```{r}
fit.glm <- glm(mpg01~cylinders+weight+displacement+horsepower,
               data=Auto, family=binomial, subset=train)
summary(fit.glm)
probs <- predict(fit.glm, Auto.test, type="response")
pred.glm <- rep(0, length(probs))
pred.glm[probs>0.5] <- 1
mean(pred.glm != mpg01.test)
```
The test error of the model obtained is 12.09%

### (g)
```{r}
library(class)
train.X <- cbind(cylinders, weight, displacement, horsepower)[train, ]
test.X <- cbind(cylinders, weight, displacement, horsepower)[!train, ]
train.mpg01 <- mpg01[train]
set.seed(1)
pred.knn <- knn(train.X, test.X, train.mpg01, k=1)
mean(pred.knn != mpg01.test)
pred.knn = knn(train.X, test.X, train.mpg01, k=10)
mean(pred.knn != mpg01.test)
pred.knn = knn(train.X, test.X, train.mpg01, k=100)
mean(pred.knn != mpg01.test)
```
K=1, I obtain 15.38% test error rate.
K=10, I obtain 16.48% test error rate.
K=100, I obtain 14.29% test error rate. A K vlaue of 100 seems to perform the best.

## Exercise 4 (Applied: Comparison of Classification Methods II)
Exercise 13 (p. 173): Perform a comparison of classification methods using the Boston data set.
```{r}
library(MASS)
attach(Boston)
crim01 <- rep(0, length(crim))
crim01[crim > median(crim)] <- 1
Boston <- data.frame(Boston, crim01)

train <- 1:(length(crim)/2)
test <- (length(crim)/2+1):length(crim)
Boston.train <- Boston[train,]
Boston.test <- Boston[test,]
crim01.test <- crim01[test]

# logistic regression
fit.glm <- glm(crim01~.-crim01-crim, data=Boston, family=binomial, subset=train)
probs <- predict(fit.glm, Boston.test, type = "response")
pred.glm <- rep(0, length(probs))
pred.glm[probs>0.5] <- 1
table(pred.glm, crim01.test)
mean(pred.glm != crim01.test)

fit.glm <- glm(crim01~.-crim01-crim-chas-tax, data=Boston, family=binomial, subset=train)
probs <- predict(fit.glm, Boston.test, type = "response")
pred.glm <- rep(0, length(probs))
pred.glm[probs>0.5] <- 1
mean(pred.glm != crim01.test)
```
For the logistic regression, with various subsets of the predictors, I get test error rate of 18.18% and 18.58%.

```{r}
# LDA
fit.lda <- lda(crim01~.-crim01-crim, data=Boston, family=binomial, subset=train)
pred.lda <- predict(fit.lda, Boston.test)
mean(pred.lda$class != crim01.test)

fit.lda <- lda(crim01~.-crim01-crim-chas-tax, data=Boston, family=binomial, subset=train)
pred.lda <- predict(fit.lda, Boston.test)
mean(pred.lda$class != crim01.test)
```
For the LDA, with various subsets of the predictors, I get test error rate of 13.44% and 12.25%.

```{r}
train.X <- cbind(zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat, medv)[train,]
test.X <- cbind(zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat, medv)[test,]
train.crim01 <- crim01[train]
set.seed(1)
pred.knn <- knn(train.X, test.X, train.crim01, k=1)
mean(pred.knn != crim01.test)

pred.knn <- knn(train.X, test.X, train.crim01, k=10)
mean(pred.knn != crim01.test)

pred.knn <- knn(train.X, test.X, train.crim01, k=100)
mean(pred.knn != crim01.test)
```
K=1, I obtain 45.85% test error rate.
K=10, I obtain 11.86% test error rate.
K=100, I obtain 49.01% test error rate. A K vlaue of 10 seems to perform the best.

```{r}
# KNN(k=10) with subset of variables
train.X <- cbind(zn, nox, rm, dis, rad, ptratio, black, medv)[train,]
test.X <- cbind(zn, nox, rm, dis, rad, ptratio, black, medv)[test,]
train.crim01 <- crim01[train]
set.seed(1)
pred.knn <- knn(train.X, test.X, train.crim01, k=10)
mean(pred.knn != crim01.test)
```
K=10, with subsets of the predictors, I obtain 27.67% test error rate.
